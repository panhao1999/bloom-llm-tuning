# llm-tuning
该项目旨在学习模型微调原理，采用公开数据集 alpaca_gpt4_data_zh 对 Bloom-1.4B 模型进行微调并推理。微调技术包括：bitfit-tuning、prompt-tuning、p-tuning、prefix-tuning和lora-tuning。

数据集总数约5万条，下载地址：https://huggingface.co/datasets/shibing624/alpaca-zh

模型文件下载地址：https://huggingface.co/Langboat/bloom-1b4-zh

## Bloom模型介绍
Bloom 模型以 Transformer 架构为基础构建，Transformer 架构的自注意力机制能让模型有效处理序列数据中的长距离依赖关系，在自然语言处理任务中表现卓越。Bloom 模型采用了与 GPT 系列相似的解码器（Decoder）架构，使其在生成式任务上具有出色性能。

## 训练

## 推理



